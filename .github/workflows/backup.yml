name: Automated Website Backup

on:
  # Run on schedule (daily at 2 AM UTC)
  schedule:
    - cron: '0 2 * * *'
  
  # Run on manual trigger
  workflow_dispatch:
  
  # Run on push to main branch
  push:
    branches: [ main, staging/performance-optimization ] # Add your development branch here
    paths:
      - 'src/content/**'
      - 'public/**'
      - 'netlify/**'
      - 'schemas/**'
      - 'src/components/**'
      - 'src/pages/**'
      - '.github/workflows/backup.yml' # Trigger when workflow is updated
      - 'scripts/production-backup.js' # Trigger when backup script is updated

jobs:
  backup:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Fetch full history for Git info
    
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        cache: 'npm'
    
    - name: Install dependencies
      run: npm ci
    
    - name: Verify backup script exists
      run: |
        if [ ! -f "scripts/production-backup.js" ]; then
          echo "‚ùå Error: backup script not found!"
          exit 1
        fi
        echo "‚úÖ Backup script found"
        ls -la scripts/production-backup.js
    
    - name: Run backup system
      env:
        NODE_ENV: production
        BACKUP_DIR: ./production-backups
        MAX_BACKUPS: 10
        LOG_LEVEL: info
      run: |
        echo "üöÄ Starting backup process..."
        echo "üìÅ Backup directory: $BACKUP_DIR"
        echo "üîß Environment: $NODE_ENV"
        echo "üìÇ Current directory: $(pwd)"
        echo "üìÑ Script path: scripts/production-backup.js"
        
        # Create backup directory if it doesn't exist
        mkdir -p "$BACKUP_DIR"
        
        # Run the backup script directly with explicit error handling
        set +e  # Don't exit on error immediately
        node scripts/production-backup.js
        EXIT_CODE=$?
        set -e  # Re-enable exit on error
        
        if [ $EXIT_CODE -ne 0 ]; then
          echo "‚ùå Backup script exited with code: $EXIT_CODE"
          echo "Checking for partial backup..."
        fi
        
        # Check if backup was created
        if [ -d "$BACKUP_DIR" ]; then
          echo "‚úÖ Backup directory exists"
          BACKUP_COUNT=$(ls -1 "$BACKUP_DIR" 2>/dev/null | wc -l)
          echo "üì¶ Backup count: $BACKUP_COUNT"
          if [ $BACKUP_COUNT -gt 0 ]; then
            echo "üìã Recent backups:"
            ls -lah "$BACKUP_DIR" | head -10
          else
            echo "‚ö†Ô∏è Warning: Backup directory is empty"
          fi
        else
          echo "‚ùå Error: Backup directory not found after script execution"
          exit 1
        fi
        
        # Exit with the script's exit code
        if [ $EXIT_CODE -ne 0 ]; then
          exit $EXIT_CODE
        fi
    
    - name: Upload backup artifacts
      uses: actions/upload-artifact@v4
      with:
        name: website-backup-${{ github.run_number }}
        path: production-backups/
        retention-days: 30
        if-no-files-found: warn
    
    - name: Create backup summary
      run: |
        echo "## ü§ñ Website Backup Report" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Backup completed:** $(date)" >> $GITHUB_STEP_SUMMARY
        echo "**Triggered by:** ${{ github.event_name }}" >> $GITHUB_STEP_SUMMARY
        echo "**Commit:** ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [ -d "production-backups" ]; then
          echo "**Backup files:**" >> $GITHUB_STEP_SUMMARY
          ls -lah production-backups/ | head -20 >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Backup count:** $(ls -1 production-backups/ | wc -l)" >> $GITHUB_STEP_SUMMARY
        else
          echo "‚ö†Ô∏è **Warning:** Backup directory not found!" >> $GITHUB_STEP_SUMMARY
        fi
    
    - name: Debug on failure
      if: failure()
      run: |
        echo "‚ùå Backup failed! Debugging information:"
        echo "Current directory: $(pwd)"
        echo "Node version: $(node --version)"
        echo "NPM version: $(npm --version)"
        if [ -d "production-backups" ]; then
          echo "Backup directory exists:"
          ls -lah production-backups/
        else
          echo "Backup directory does not exist"
        fi
        if [ -f "scripts/production-backup.js" ]; then
          echo "Backup script exists"
        else
          echo "Backup script NOT found!"
        fi
    
    - name: Notify on failure
      if: failure()
      uses: 8398a7/action-slack@v3
      with:
        status: failure
        webhook_url: ${{ secrets.SLACK_WEBHOOK_URL }}
        text: "‚ùå Website backup failed! Check the logs for details."
      env:
        SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
      continue-on-error: true

  # Optional: Upload to cloud storage
  upload-to-cloud:
    needs: backup
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule'  # Only for scheduled backups
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Download backup artifacts
      uses: actions/download-artifact@v4
      with:
        name: website-backup-${{ github.run_number }}
        path: production-backups/
    
    - name: Upload to Google Drive (optional)
      if: ${{ secrets.GOOGLE_DRIVE_FOLDER_ID != '' }}
      uses: burnett01/rsync-deployments@6.0.0
      with:
        switches: -avzr --delete
        path: production-backups/
        remote_path: ${{ secrets.GOOGLE_DRIVE_FOLDER_ID }}
        remote_host: ${{ secrets.GOOGLE_DRIVE_HOST }}
        remote_user: ${{ secrets.GOOGLE_DRIVE_USER }}
        remote_key: ${{ secrets.GOOGLE_DRIVE_KEY }}
    
    - name: Upload to AWS S3 (optional)
      if: ${{ secrets.AWS_ACCESS_KEY_ID != '' }}
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ secrets.AWS_REGION }}
    
    - name: Sync to S3
      if: ${{ secrets.AWS_ACCESS_KEY_ID != '' }}
      run: |
        aws s3 sync production-backups/ s3://${{ secrets.S3_BUCKET }}/website-backups/ \
          --exclude "*.tar.gz" \
          --storage-class STANDARD_IA 